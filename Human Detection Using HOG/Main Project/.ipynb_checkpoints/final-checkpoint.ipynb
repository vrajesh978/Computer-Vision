{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREWIT_OPERATOR_GX = np.array([[-1,0,1],\n",
    "\t\t\t\t\t\t\t\t[-1,0,1],\n",
    "\t\t\t\t\t\t\t\t[-1,0,1]])\n",
    "\n",
    "PREWIT_OPERATOR_GY = np.array([[1,1,1],\n",
    "\t\t\t\t\t\t\t\t[0,0,0],\n",
    "\t\t\t\t\t\t\t\t[-1,-1,-1]])\n",
    "\n",
    "\n",
    "def convolution(img,g):\n",
    "\t\"\"\"\n",
    "\t\tparameters:\n",
    "\t\t\t@param 1 : img, image matrix\n",
    "\t\t\t@param 2 : g, kernel 3x3 prewitt operator  \n",
    "\t\t@return : img_conv, matrix performing convolution img*g\n",
    "\t\"\"\"\n",
    "\trows,cols = img.shape\n",
    "\theightG,widthG = g.shape[0]//2,g.shape[1]//2\n",
    "\timg_conv = np.zeros(img.shape)\n",
    "\tfor i in range(1,rows-1):\n",
    "\t\tfor j in range(1,cols - 1):\n",
    "\t\t\timg_conv[i,j] = 0\n",
    "\t\t\tfor k in range(-heightG, heightG + 1):\n",
    "\t\t\t\tfor m in range(-widthG , widthG + 1):\n",
    "\t\t\t\t\timg_conv[i,j] = img_conv[i,j] + g[heightG+k,widthG+m] * img[i+k,j+m]\n",
    "\t\t\tif(img_conv[i,j] < 0):\n",
    "\t\t\t\timg_conv[i,j] = abs(img_conv[i,j]) # taking absolute value\n",
    "\t\t\timg_conv[i,j] = img_conv[i,j] / 3.0 # normalizing gradients\n",
    "\treturn img_conv\n",
    "\n",
    "def prewitt(img):\n",
    "\t\"\"\"\n",
    "\t\tparameters:\n",
    "\t\t\t@param1 : img, numpy array of the image.\n",
    "\t\t@return : prewittGx, image matrix after img*PREWIT_OPERATOR_GX\n",
    "\t\t@return : prewittGy, image matrix after img*PREWIT_OPERATOR_GY\n",
    "\t\"\"\"\n",
    "\tprewittGx = convolution(img,PREWIT_OPERATOR_GX)\n",
    "\tprewittGy = convolution(img,PREWIT_OPERATOR_GY)\n",
    "\treturn prewittGx,prewittGy\n",
    "\n",
    "def compute_gradient_magnitude_angle(gx,gy):\n",
    "\t\"\"\"\n",
    "\tParameters: \n",
    "\t\t@param1 : gx, horizontal gradient\n",
    "\t\t@param2 : gy, vertical gradient\n",
    "\t@return: gradient magnitude and gradient angle.\n",
    "\t\"\"\"\n",
    "\tgradient_magnitude=np.zeros((gx.shape[0],gx.shape[1]))\n",
    "\tgradient_angle=np.zeros((gx.shape[0],gx.shape[1]))\n",
    "\t\n",
    "\tfor i in range(gx.shape[0]):\n",
    "\t\tfor j in range(gx.shape[1]):\n",
    "\t\t\tgradient_magnitude[i,j] = math.sqrt((gx[i,j]*gx[i,j]) + (gy[i,j]*gy[i,j]))\n",
    "\t\t\tif(gx[i,j]==0) and (gy[i,j]==0):\n",
    "\t\t\t\tgradient_angle[i,j] = 0.0\n",
    "\t\t\telif(gx[i,j]==0):\n",
    "\t\t\t\tif(gy[i,j]>0):\n",
    "\t\t\t\t\tgradient_angle[i,j] = 90.0\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tgradient_angle[i,j] = -90.0\n",
    "\t\t\telse:\n",
    "\t\t\t\tgradient_angle[i,j] = math.degrees(math.atan(gy[i,j]/gx[i,j]))\n",
    "\t\t\t\tif(gradient_angle[i,j]<0):\n",
    "\t\t\t\t\tgradient_angle[i,j]=180+gradient_angle[i,j]\n",
    "\n",
    "\t\t\t\tif(gradient_angle[i,j]==-0):\n",
    "\t\t\t\t\tgradient_angle[i,j]=0\n",
    "\treturn gradient_magnitude/1.4142,gradient_angle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateHOG(img,gradient_magnitude,gradient_angle):\n",
    "\tcellHistogram,row,col = calculateCellHisto(img,gradient_magnitude,gradient_angle)\n",
    "\tfeature_vector = calculateFeatureVector(cellHistogram,row,col)\n",
    "\treturn feature_vector\n",
    "\n",
    "def calculateCellHisto(img,gradient_magnitude,gradient_angle):\n",
    "\theight,width = img.shape\n",
    "\trow=math.floor(height/8)\n",
    "\tcol=math.floor(width/8)\n",
    "\trow1=0\n",
    "\tcol1=0\n",
    "\tcount=0\n",
    "\tcellHistStrct=np.zeros((row,col,9))\n",
    "\tfor r in range(0,height-8,8):\n",
    "\t\tfor c in range(0,width-8,8):\n",
    "\t\t\ti_row=r\n",
    "\t\t\tlim_i_row=i_row + 8\n",
    "\t\t\thistogram = [0]*9\n",
    "\t\t\tfor i in range(i_row,lim_i_row):\n",
    "\t\t\t\tj_col=c\n",
    "\t\t\t\tlim_j_col=j_col+8\n",
    "\t\t\t\tfor j in range(j_col,lim_j_col):\n",
    "\t\t\t\t\tif(gradient_angle[i,j] == 0 or gradient_angle[i,j] == 180):\n",
    "\t\t\t\t\t\thistogram[0] += gradient_magnitude[i,j]\n",
    "\t\t\t\t\telif(gradient_angle[i,j] > 0 and gradient_angle[i,j] < 20):\n",
    "\t\t\t\t\t\thistogram[0] += ((20-gradient_angle[i,j])/20)*gradient_magnitude[i,j]\n",
    "\t\t\t\t\t\thistogram[1] += ((gradient_angle[i,j]-0)/20)*gradient_magnitude[i,j]\n",
    "\t\t\t\t\telif(gradient_angle[i,j] == 20):\n",
    "\t\t\t\t\t\thistogram[1] += gradient_magnitude[i,j]\n",
    "\t\t\t\t\telif(gradient_angle[i,j] > 20 and gradient_angle[i,j] < 40):\n",
    "\t\t\t\t\t\thistogram[1] += ((40-gradient_angle[i,j])/20)*gradient_magnitude[i,j]\n",
    "\t\t\t\t\t\thistogram[2] += ((gradient_angle[i,j]-20)/20)*gradient_magnitude[i,j]\n",
    "\t\t\t\t\telif(gradient_angle[i,j] == 40):\n",
    "\t\t\t\t\t\thistogram[2] += gradient_magnitude[i,j]\n",
    "\t\t\t\t\telif(gradient_angle[i,j] > 40 and gradient_angle[i,j] < 60):\n",
    "\t\t\t\t\t\thistogram[2] += ((60-gradient_angle[i,j])/20)*gradient_magnitude[i,j]\n",
    "\t\t\t\t\t\thistogram[3] += ((gradient_angle[i,j]-40)/20)*gradient_magnitude[i,j]\n",
    "\t\t\t\t\telif(gradient_angle[i,j] == 60):\n",
    "\t\t\t\t\t\thistogram[3] += gradient_magnitude[i,j]\n",
    "\t\t\t\t\telif(gradient_angle[i,j] > 60 and gradient_angle[i,j] < 80):\n",
    "\t\t\t\t\t\thistogram[3] += ((80-gradient_angle[i,j])/20)*gradient_magnitude[i,j]\n",
    "\t\t\t\t\t\thistogram[4] += ((gradient_angle[i,j]-60)/20)*gradient_magnitude[i,j]\n",
    "\t\t\t\t\telif(gradient_angle[i,j] == 80):\n",
    "\t\t\t\t\t\thistogram[4] += gradient_magnitude[i,j]\n",
    "\t\t\t\t\telif(gradient_angle[i,j] > 80 and gradient_angle[i,j] < 100):\n",
    "\t\t\t\t\t\thistogram[4] += ((100-gradient_angle[i,j])/20)*gradient_magnitude[i,j]\n",
    "\t\t\t\t\t\thistogram[5] += ((gradient_angle[i,j]-80)/20)*gradient_magnitude[i,j]\n",
    "\t\t\t\t\telif(gradient_angle[i,j] == 100):\n",
    "\t\t\t\t\t\thistogram[5] += gradient_magnitude[i,j]\n",
    "\t\t\t\t\telif(gradient_angle[i,j] > 100 and gradient_angle[i,j] < 120):\n",
    "\t\t\t\t\t\thistogram[5] += ((120-gradient_angle[i,j])/20)*gradient_magnitude[i,j]\n",
    "\t\t\t\t\t\thistogram[6] += ((gradient_angle[i,j]-100)/20)*gradient_magnitude[i,j]\n",
    "\t\t\t\t\telif(gradient_angle[i,j] == 120):\n",
    "\t\t\t\t\t\thistogram[6] += gradient_magnitude[i,j]\n",
    "\t\t\t\t\telif(gradient_angle[i,j] > 120 and gradient_angle[i,j] < 140):\n",
    "\t\t\t\t\t\thistogram[6] += ((140-gradient_angle[i,j])/20)*gradient_magnitude[i,j]\n",
    "\t\t\t\t\t\thistogram[7] += ((gradient_angle[i,j]-120)/20)*gradient_magnitude[i,j]\n",
    "\t\t\t\t\telif(gradient_angle[i,j] == 140):\n",
    "\t\t\t\t\t\thistogram[7] += gradient_magnitude[i,j]\n",
    "\t\t\t\t\telif(gradient_angle[i,j] > 140 and gradient_angle[i,j] < 160):\n",
    "\t\t\t\t\t\thistogram[7] += ((160-gradient_angle[i,j])/20)*gradient_magnitude[i,j]\n",
    "\t\t\t\t\t\thistogram[8] += ((gradient_angle[i,j]-140)/20)*gradient_magnitude[i,j]\n",
    "\t\t\t\t\telif(gradient_angle[i,j] == 160):\n",
    "\t\t\t\t\t\thistogram[8] += gradient_magnitude[i,j]\n",
    "\t\t\t\t\telif(gradient_angle[i,j] > 160):\n",
    "\t\t\t\t\t\thistogram[8] += ((180-gradient_angle[i,j])/20)*gradient_magnitude[i,j]\n",
    "\t\t\t\t\t\thistogram[0] += ((gradient_angle[i,j]-160)/20)*gradient_magnitude[i,j]\n",
    "\t\t\tcount=count+1\n",
    "\t\t\tcellHistStrct[row1][col1]=histogram\n",
    "\t\t\tcol1=col1+1\n",
    "\t\trow1=row1+1\n",
    "\t\tcol1=0\n",
    "\treturn cellHistStrct,row,col\n",
    "\n",
    "\n",
    "def calculateFeatureVector(cellHistogram,row,col):\n",
    "#BLOCKS\n",
    "\tvalue=(row-1)*(col-1)*4*9\n",
    "\tsum_=0.0\n",
    "\n",
    "\tfeature_vector=np.zeros(1)\n",
    "\tfor i in range(0,row-1):\n",
    "\t\tfor j in range(0,col-1):\n",
    "\t\t\ttemp_block=np.zeros(1)\n",
    "\t\t\ttemp_block=np.append(temp_block,cellHistogram[i][j])\n",
    "\t\t\ttemp_block=np.append(temp_block,cellHistogram[i][j+1])\n",
    "\t\t\ttemp_block=np.append(temp_block,cellHistogram[i+1][j])\n",
    "\t\t\ttemp_block=np.append(temp_block,cellHistogram[i+1][j+1])\n",
    "\t\t\ttemp_block=temp_block[1:]\n",
    "\t\t\tfor k in range(0,36):\n",
    "\t\t\t\tsum_=sum_ + (temp_block[k] * temp_block[k])\n",
    "\t\t\tl2_norm_factor=np.sqrt(sum_)\n",
    "\t\t\tblock = np.zeros(temp_block.shape)\n",
    "\t\t\tfor k in range (0,36):\n",
    "\t\t\t\tif l2_norm_factor == 0:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tblock[k]=temp_block[k]/l2_norm_factor\n",
    "\t\t\tfeature_vector = np.append(feature_vector,block)\n",
    "\t\n",
    "\tfeature_vector=feature_vector[1:]\n",
    "\treturn feature_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def d_Sigmoid(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "\n",
    "def ReLu(x):\n",
    "    return x * (x > 0)\n",
    "\n",
    "def d_ReLu(x):\n",
    "    return 1. * (x > 0)\n",
    "\n",
    "\n",
    "def trainNeuralNetwork(X,Y,no_hidden_neurons):\n",
    "    '''\n",
    "    parameter : \n",
    "        @param1: X, input list of all training sample's feature vector. \n",
    "        @param2: Y, list of actual training label. \n",
    "        @param3: no_hidden_neurons, number of hidden layer neurons.\n",
    "        @return : dictionary , it contains model's parmaeters (weight and bias)\n",
    "    '''\n",
    "    np.random.seed(1)\n",
    "    '''random initialization of weight and bias'''\n",
    "    w1 = np.random.randn(no_hidden_neurons, len(X[0])) * 0.01\n",
    "    b1 = np.zeros((no_hidden_neurons,1)) \n",
    "    w2 = np.random.randn(1,no_hidden_neurons) * 0.01\n",
    "    b2 = np.zeros((1,1))\n",
    "    \n",
    "    dictionary = {} #This will contain updated weight and bias.    \n",
    "    cost_avg = 0.0 # average cost of our network\n",
    "    old_cost = 0.0\n",
    "\n",
    "    \"\"\" Our neural network will train maximum up to 200 epoch. \n",
    "    if cost between two epochs is less than 0.02, we will stop. \n",
    "    Because we know that our weights does not change too much.\"\"\"\n",
    "    for i in range(0,100):\n",
    "        cost = 0.0\n",
    "        for j in range(0,len(X)):\n",
    "            q = X[j]    #getting feature vector from the list.\n",
    "            '''Neural network train'''\n",
    "            #forward pass\n",
    "            z1 = w1.dot(q)+ b1   \n",
    "            a1 = ReLu(z1)\n",
    "            z2 = w2.dot(a1) + b2\n",
    "            a2 = sigmoid(z2)\n",
    "            cost += (a2-Y[j])*(a2-Y[j])  #findng the cost of the every image and sum their cost.\n",
    "\n",
    "            # Backward Propogation\n",
    "            dz2 = (a2-Y[j])  *  d_Sigmoid(a2)\n",
    "            dw2 = np.dot(dz2,a1.T)\n",
    "            db2 = np.sum(dz2,axis=1, keepdims=True)\n",
    "\n",
    "            dz1 = w2.T.dot(dz2) * d_ReLu(a1)\n",
    "            dw1 =  np.dot(dz1,q.T)\n",
    "            db1 =  np.sum(dz1,axis=1, keepdims=True)\n",
    "\n",
    "            #updating weights. Here 0.01 is the learning rate\n",
    "            w1 = w1 - 0.01*dw1  \n",
    "            w2 = w2 - 0.01*dw2\n",
    "            b1 = b1 - 0.01*db1\n",
    "            b2 = b2 - 0.01*db2\n",
    "            \n",
    "        cost_avg = cost/len(X)    #taking average cost\n",
    "        print(\"Epoch = \",i,\"cost_avg = \",cost_avg)\n",
    "        dictionary = {'w1':w1,'b1':b1,'w2':w2,'b2':b2} #save our updated weights. So that we can use them while testing.\n",
    "        # if cost between two epochs is less than 0.02, we will stop. Because we know that our weights does not change too much.\n",
    "        # if(abs(old_cost-cost_avg)<0.002):   \n",
    "        #     return dictionary\n",
    "        # else:\n",
    "        #     old_cost = cost_avg\n",
    "    return dictionary\n",
    "\n",
    "def saveModelFile(dictionary,name):\n",
    "    \"\"\"\n",
    "    Saving our model's parameter so we dont have to start all the process again.\n",
    "    @param1: dictionary, containg our trained model parameters\n",
    "    \"\"\"\n",
    "    np.save(str(name)+\".npy\",dictionary)\n",
    "    print(\"Successfully saved model file as\",str(name),\".npy\")\n",
    "\n",
    "def loadModelFile(name):\n",
    "    \"\"\"\n",
    "        Loading our modelfile.\n",
    "        @return : dictionary, containing our trained model parameters\n",
    "    \"\"\"\n",
    "    print(\"Loading model file\")\n",
    "    dictionary = np.load(str(name)+\".npy\")\n",
    "    print(\"Successfully loaded model files\")\n",
    "    return dictionary[()]\n",
    "\n",
    "def predict(X_test,dictionary):\n",
    "    \"\"\"\n",
    "        Predict the newly seen data.\n",
    "        @param1: X_test, new data that is not seen by our model yet.\n",
    "        @param2: dictionary, containing our trained model parameters\n",
    "        @return : 1 if human is in the picture, 0 if human is not in the picture.\n",
    "    \"\"\"\n",
    "    w1,w2,b1,b2 = dictionary['w1'],dictionary['w2'],dictionary['b1'],dictionary['b2']\n",
    "    z1 = w1.dot(X_test)+ b1   \n",
    "    a1 = ReLu(z1)\n",
    "    z2 = w2.dot(a1) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "    return a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateFeatureVector_from_img_path(img_path):\n",
    "\t\"\"\"\n",
    "\t@param 1: img_path, full path of the image\n",
    "\t@return feature_vector, contains features which is used as an input to our neural network. dimension [7524 x 1]\n",
    "\t\"\"\"\n",
    "\timg_c = cv2.imread(img_path) \n",
    "\timg_gray_scale = np.round(0.299*img_c[:,:,2] + 0.587*img_c[:,:,1] + 0.114*img_c[:,:,0]) # converting image into grayscale.\n",
    "\tgx,gy = prewitt(img_gray_scale) # finding horizontal gradient and vertical gradient.\n",
    "\tgradient_magnitude,gradient_angle = compute_gradient_magnitude_angle(gx,gy) # finding gradient magnitude and gradient angle.\n",
    "\tfeature_vector = calculateHOG(img_gray_scale,gradient_magnitude,gradient_angle)  #calculate hog descriptior\n",
    "\tfeature_vector = feature_vector.reshape(feature_vector.shape[0],1) # reshaping our vector. making dimension [7524 x 1]\n",
    "\treturn feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Start finding feature vector for training samples-------------\n",
      "---------Finished finding feature vector for training samples-----------\n",
      "---------Start finding feature vector for testing samples-------------\n",
      "---------Finished finding feature vector for testing samples-----------\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PATH = [\"Images/Train_Positive\",\"Images/Train_Negative\"]\n",
    "TEST_PATH = [\"Images/Test_Positive\",\"Images/Test_Neg\"]\n",
    "y_train = []\n",
    "y_test = []\n",
    "\n",
    "train_images_feature_vector_list = []\n",
    "test_images_feature_vector_list = []\n",
    "print(\"---------Start finding feature vector for training samples-------------\")\n",
    "i=1\n",
    "for path in TRAIN_PATH:\n",
    "\tfor root,dirs,files in os.walk(path):\n",
    "\t\tfor name in files:\n",
    "\t\t\ttrain_images_feature_vector_list.append(calculateFeatureVector_from_img_path(path+\"/\"+str(name)))\n",
    "\t\t\ty_train.append(np.array([[i]]))\n",
    "\ti = 0\n",
    "print(\"---------Finished finding feature vector for training samples-----------\")\n",
    "print(\"---------Start finding feature vector for testing samples-------------\")\n",
    "i = 1\n",
    "for path in TEST_PATH:\n",
    "\tfor root,dirs,files in os.walk(path):\n",
    "\t\tfor name in files:\n",
    "\t\t\ttest_images_feature_vector_list.append(calculateFeatureVector_from_img_path(path+\"/\"+str(name)))\n",
    "\t\t\ty_test.append(np.array([[i]]))\n",
    "\ti = 0\n",
    "print(\"---------Finished finding feature vector for testing samples-----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------Start training where  500  hidden neurons----------------\n",
      "Epoch =  0 cost_avg =  [[ 0.25006395]]\n",
      "20\n",
      "Epoch =  1 cost_avg =  [[ 0.24997761]]\n",
      "20\n",
      "Epoch =  2 cost_avg =  [[ 0.2498913]]\n",
      "20\n",
      "Epoch =  3 cost_avg =  [[ 0.24980547]]\n",
      "20\n",
      "Epoch =  4 cost_avg =  [[ 0.24971988]]\n",
      "20\n",
      "Epoch =  5 cost_avg =  [[ 0.24963439]]\n",
      "20\n",
      "Epoch =  6 cost_avg =  [[ 0.24954911]]\n",
      "20\n",
      "Epoch =  7 cost_avg =  [[ 0.24946315]]\n",
      "20\n",
      "Epoch =  8 cost_avg =  [[ 0.24937719]]\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Let's train our neural network.\"\"\"\n",
    "for no_hidden_neurons in [500]:\n",
    "\tprint(\"-------------------Start training where \",no_hidden_neurons,\" hidden neurons----------------\")\n",
    "\tmodel = trainNeuralNetwork(train_images_feature_vector_list,y_train,no_hidden_neurons)\n",
    "\tprint(\"Saving model in data\",str(no_hidden_neurons),\".npy file\")\n",
    "\tsaveModelFile(model,\"data\"+str(no_hidden_neurons))\n",
    "\tprint(\"successfully trained our neural network containg \",no_hidden_neurons,\" hidden neurons.\")\n",
    "\tprint(\"--------------------------------------------------------------------------------\")\n",
    "\tfor test_img in test_images_feature_vector_list:\n",
    "\t\tprint(predict(test_img,model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.78507565e-16]]\n",
      "[[  7.34070958e-21]]\n",
      "[[ 0.03602287]]\n",
      "[[ 0.9934619]]\n",
      "[[  3.79946584e-20]]\n",
      "[[  3.89146196e-18]]\n",
      "[[  2.57179481e-09]]\n",
      "[[  7.74581252e-06]]\n",
      "[[  3.37736532e-06]]\n",
      "[[  9.00142923e-06]]\n"
     ]
    }
   ],
   "source": [
    "for test_img in test_images_feature_vector_list:\n",
    "\tprint(predict(test_img,model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list(zip(train_images_feature_vector_list, y_train))\n",
    "\n",
    "random.shuffle(c)\n",
    "\n",
    "train_images_feature_vector_list, y_train = zip(*c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 0.06344912],\n",
      "       [ 0.29214106],\n",
      "       [ 0.32872375],\n",
      "       ..., \n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ]]), array([[ 0.0929016 ],\n",
      "       [ 0.32344913],\n",
      "       [ 0.32093431],\n",
      "       ..., \n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ]]), array([[ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       ..., \n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.]]), array([[ 0.49575755],\n",
      "       [ 0.39667622],\n",
      "       [ 0.20087675],\n",
      "       ..., \n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ]]), array([[ 0.53515391],\n",
      "       [ 0.41952606],\n",
      "       [ 0.08704727],\n",
      "       ..., \n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ]]), array([[ 0.        ],\n",
      "       [ 0.17554519],\n",
      "       [ 0.50497155],\n",
      "       ..., \n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ]]), array([[ 0.13074181],\n",
      "       [ 0.27775026],\n",
      "       [ 0.2107199 ],\n",
      "       ..., \n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ]]), array([[ 0.07565519],\n",
      "       [ 0.05826886],\n",
      "       [ 0.03498128],\n",
      "       ..., \n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ]]), array([[ 0.00747014],\n",
      "       [ 0.00554254],\n",
      "       [ 0.01233387],\n",
      "       ..., \n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ]]), array([[ 0.05145785],\n",
      "       [ 0.02724068],\n",
      "       [ 0.13878234],\n",
      "       ..., \n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ]]), array([[ 0.00364536],\n",
      "       [ 0.0238458 ],\n",
      "       [ 0.04299066],\n",
      "       ..., \n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ]]), array([[ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       ..., \n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.]]), array([[ 0.10432587],\n",
      "       [ 0.10069465],\n",
      "       [ 0.068728  ],\n",
      "       ..., \n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ]]), array([[ 0.0545083 ],\n",
      "       [ 0.13783985],\n",
      "       [ 0.142361  ],\n",
      "       ..., \n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ]]), array([[ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       ..., \n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.]]), array([[ 0.07461199],\n",
      "       [ 0.21835691],\n",
      "       [ 0.22316131],\n",
      "       ..., \n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ]]), array([[ 0.18557548],\n",
      "       [ 0.0695132 ],\n",
      "       [ 0.02629382],\n",
      "       ..., \n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ]]), array([[ 0.03805023],\n",
      "       [ 0.08395639],\n",
      "       [ 0.05444324],\n",
      "       ..., \n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ]]), array([[  8.94438408e-06],\n",
      "       [  3.78705895e-02],\n",
      "       [  2.53620045e-01],\n",
      "       ..., \n",
      "       [  0.00000000e+00],\n",
      "       [  0.00000000e+00],\n",
      "       [  0.00000000e+00]]), array([[ 0.00299302],\n",
      "       [ 0.01763302],\n",
      "       [ 0.02106641],\n",
      "       ..., \n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ]]))\n",
      "(array([[1]]), array([[0]]), array([[0]]), array([[1]]), array([[0]]), array([[1]]), array([[0]]), array([[0]]), array([[1]]), array([[1]]), array([[1]]), array([[0]]), array([[0]]), array([[0]]), array([[1]]), array([[1]]), array([[1]]), array([[0]]), array([[1]]), array([[0]]))\n"
     ]
    }
   ],
   "source": [
    "print(train_images_feature_vector_list)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
